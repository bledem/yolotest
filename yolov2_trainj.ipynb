{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import chainer\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from chainer import serializers, optimizers, Variable, iterators,training, cuda\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainer.training import extensions\n",
    "from chainer import Reporter, report, report_scope\n",
    "import chainer.functions as F\n",
    "from yolov2 import *\n",
    "from lib.utils import *\n",
    "from lib.preprocess import _offset_boxes, clip_boxes\n",
    "#from lib.image_generator import *\n",
    "from lib.data_generator import *\n",
    "from darknet19 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_conv_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.conv%d\" % i)\n",
    "        dst_layer = eval(\"dst.conv%d\" % i)\n",
    "        dst_layer.W = src_layer.W\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bias_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bias%d\" % i)\n",
    "        dst_layer = eval(\"dst.bias%d\" % i)\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bn_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bn%d\" % i)\n",
    "        dst_layer = eval(\"dst.bn%d\" % i)\n",
    "        dst_layer.N = src_layer.N\n",
    "        dst_layer.avg_var = src_layer.avg_var\n",
    "        dst_layer.avg_mean = src_layer.avg_mean\n",
    "        dst_layer.gamma = src_layer.gamma\n",
    "        dst_layer.eps = src_layer.eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert(batch, device):\n",
    "\n",
    "    #for pair in batch:\n",
    "        #print(pair[1])\n",
    "    return chainer.dataset.convert.concat_examples(batch, device, padding=0)\n",
    "\n",
    "def print_obs(t):\n",
    "    print(\"trainer.observation\", trainer.observation)\n",
    "    print(\"updater.loss\", updater.loss_func)\n",
    "    \n",
    "def save_model(t):\n",
    "    \n",
    "    serializers.save_hdf5(\"%s/yolov2_load.model\" % (\"./backup/result\"), model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "#train_sizes = [320, 352, 384, 416, 448]\n",
    "#train_sizes = [448]\n",
    "initial_weight_file = \"./backup/result/yolov2_load.model\"\n",
    "#initial_weight_file = None\n",
    "trained_weight_file = \"./darknet19_448.model\"\n",
    "snapshot=None\n",
    "#snapshot = \"./backup/result/snapshot_iter_4968\"\n",
    "backup_path = \"backup\"\n",
    "backup_file = \"%s/backup.model\" % (backup_path)\n",
    "batch_size =6\n",
    "epoch = 1000\n",
    "max_batches = 20000\n",
    "learning_rate = 1e-5\n",
    "learning_schedules = { \n",
    "    \"0\"    : 1e-5,\n",
    "    \"500\"  : 1e-4,\n",
    "    \"10000\": 1e-5,\n",
    "    \"20000\": 1e-6 \n",
    "}\n",
    "\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "n_classes = 3\n",
    "n_boxes = 5\n",
    "partial_layer = 18\n",
    "\n",
    "start = time.time()\n",
    "imageNet_data = ImageNet_data(\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_img\",\n",
    "\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_bbox\", \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt\", n_classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing with serial_load backup weight\n"
     ]
    }
   ],
   "source": [
    "trained_model = Darknet19()\n",
    "serializers.load_npz(trained_weight_file, trained_model) # load saved model\n",
    "trained_model = Darknet19Predictor(trained_model)\n",
    "if initial_weight_file is None:\n",
    "    print(\"inititializing with the darknet19_448 weights\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    copy_conv_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bias_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bn_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "elif not (snapshot is None) :\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_npz(snapshot, model)\n",
    "\n",
    "else :\n",
    "    print(\"initializing with serial_load backup weight\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_hdf5(initial_weight_file, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predictor.train = True\n",
    "model.predictor.finetune = False  ####or True ??\n",
    "cuda.get_device(0).use()\n",
    "model.to_gpu()\n",
    "\n",
    "optimizer = optimizers.MomentumSGD(lr=learning_rate, momentum=momentum)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "model.predictor.conv1.disable_update()\n",
    "model.predictor.conv2.disable_update()\n",
    "model.predictor.conv3.disable_update()\n",
    "model.predictor.conv4.disable_update()\n",
    "model.predictor.conv5.disable_update()\n",
    "model.predictor.conv6.disable_update()\n",
    "model.predictor.conv7.disable_update()\n",
    "model.predictor.conv8.disable_update()\n",
    "model.predictor.conv9.disable_update()\n",
    "model.predictor.conv10.disable_update()\n",
    "model.predictor.conv11.disable_update()\n",
    "model.predictor.conv12.disable_update()\n",
    "model.predictor.conv13.disable_update()\n",
    "model.predictor.conv14.disable_update()\n",
    "model.predictor.conv15.disable_update()\n",
    "model.predictor.conv16.disable_update()\n",
    "#model.predictor.conv17.disable_update()\n",
    "#model.predictor.conv18.disable_update()\n",
    "#model.predictor.conv19.disable_update()\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(weight_decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(inputs, train=True):\n",
    "    #we take only one input\n",
    "    img, label= inputs\n",
    "    boxes = label.copy()\n",
    "    im = img.copy()\n",
    "    im = np.asarray(im, dtype=np.float32) /255.0\n",
    "    im = np.transpose(im, (1, 2, 0))\n",
    "    shape= im.shape\n",
    "    #random_angle = np.random.uniform(0, 360)\n",
    "    im, trans_param = imcv2_affine_trans(im)\n",
    "    scale, offs, flip = trans_param\n",
    "    print(\"label\", label, \"scale, offs, flip\", scale, offs, flip, \"shape init\" , shape)\n",
    "    boxes = _offset_boxes(boxes, im.shape, scale, offs, flip)\n",
    "    sample_image = im.copy()\n",
    "    boxes = np.asarray(boxes, dtype=np.float32)\n",
    "    print(\"box\", boxes)\n",
    "    box = Box(boxes[0][1]*shape(1), boxes[0][2]*shape(0), boxes[0][3]*shape(1),boxes[0][4]*shape(0))\n",
    "    cv2.rectangle(\n",
    "               sample_image,\n",
    "               box.int_left_top(), box.int_right_bottom(),\n",
    "               (255, 0, 255),\n",
    "               3\n",
    "           )\n",
    "    cv2.imshow(\"image\", sample_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"label\", boxes)\n",
    "    im = cv2.resize(im, shape)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = imcv2_recolor(im)\n",
    "    return img, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we transform data set for train\n"
     ]
    }
   ],
   "source": [
    "reporter = chainer.Reporter()\n",
    "\n",
    "\n",
    "#Create Train and test datset\n",
    "train, test = imageNet_data.train_val_test()\n",
    "\n",
    "#Transformed dataset, first creating function\n",
    "train_transf1 = partial(transform)\n",
    "print(\"we transform data set for train\")\n",
    "train_trans1 = TransformDataset(train, train_transf1)\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batch_size)\n",
    "test_iter = iterators.SerialIterator(test, batch_size, repeat=False, shuffle=True)\n",
    "test=1\n",
    "val_interval = (1 if test else 100000), 'epoch'\n",
    "log_interval = (30 if test else 1000), 'iteration'\n",
    "\n",
    "\n",
    "\n",
    "with chainer.using_config('debug', True):\n",
    "    # Set up a trainer\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, loss_func=model, converter=convert, device=0)\n",
    "    trainer = training.Trainer(updater, (100, 'epoch'), out=\"./backup/result\")\n",
    "updater.connect_trainer(trainer)\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, converter=convert, device=0), trigger=val_interval)\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "# Take a snapshot at each epoch\n",
    "#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))\n",
    "trainer.extend(extensions.snapshot(), trigger=(20, 'epoch'))\n",
    "trainer.extend(save_model,  trigger=(10, 'epoch'))\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "trainer.extend(extensions.PrintReport(\n",
    "      ['epoch', 'main/images', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=log_interval)\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "\n",
    "# Plot graph for loss for each epoch\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/loss', 'validation/main/loss'],\n",
    "        x_key='epoch', file_name='loss.png'))\n",
    "else:\n",
    "    print('Warning: PlotReport is not available in your environment')\n",
    "# Print a progress bar to stdout\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "epoch       main/images  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J0           93           25.9875                           286.419       \n",
      "\u001b[J0           273          17.3471                           531.411       \n"
     ]
    }
   ],
   "source": [
    "with chainer.using_config('debug', True):\n",
    "    print(\"start\")\n",
    "    # Run the training\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_hdf5(\"%s/yolov2_final.model\" % (\"./backup/result\"), model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
