{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import chainer\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from chainer import serializers, optimizers, Variable, iterators,training, cuda\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainer.training import extensions\n",
    "from chainer import Reporter, report, report_scope\n",
    "import chainer.functions as F\n",
    "from yolov2 import *\n",
    "from lib.utils import *\n",
    "from lib.preprocess import _offset_boxes, clip_boxes\n",
    "from transforms.transforms import *\n",
    "#from lib.image_generator import *\n",
    "from lib.data_generator import *\n",
    "from darknet19 import *\n",
    "from numpy.random import RandomState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_conv_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.conv%d\" % i)\n",
    "        dst_layer = eval(\"dst.conv%d\" % i)\n",
    "        dst_layer.W = src_layer.W\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bias_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bias%d\" % i)\n",
    "        dst_layer = eval(\"dst.bias%d\" % i)\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bn_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bn%d\" % i)\n",
    "        dst_layer = eval(\"dst.bn%d\" % i)\n",
    "        dst_layer.N = src_layer.N\n",
    "        dst_layer.avg_var = src_layer.avg_var\n",
    "        dst_layer.avg_mean = src_layer.avg_mean\n",
    "        dst_layer.gamma = src_layer.gamma\n",
    "        dst_layer.eps = src_layer.eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert(batch, device):\n",
    "\n",
    "    #for pair in batch:\n",
    "        #print(pair[1])\n",
    "    return chainer.dataset.convert.concat_examples(batch, device, padding=0)\n",
    "\n",
    "def print_obs(t):\n",
    "    print(\"trainer.observation\", trainer.observation)\n",
    "    print(\"updater.loss\", updater.loss_func)\n",
    "    \n",
    "def save_model(t):\n",
    "    \n",
    "    serializers.save_hdf5(\"%s/yolov2_load.model\" % (\"./backup/result\"), model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "#train_sizes = [320, 352, 384, 416, 448]\n",
    "#train_sizes = [448]\n",
    "initial_weight_file = \"./backup/yolov2_load.model\"\n",
    "#initial_weight_file = None\n",
    "trained_weight_file = \"./darknet19_448.model\"\n",
    "snapshot=None\n",
    "#snapshot = \"./backup/result/snapshot_iter_4968\"\n",
    "backup_path = \"backup\"\n",
    "backup_file = \"%s/backup.model\" % (backup_path)\n",
    "batch_size =6\n",
    "epoch = 1000\n",
    "max_batches = 20000\n",
    "learning_rate = 1e-5\n",
    "learning_schedules = { \n",
    "    \"0\"    : 1e-5,\n",
    "    \"500\"  : 1e-4,\n",
    "    \"10000\": 1e-5,\n",
    "    \"20000\": 1e-6 \n",
    "}\n",
    "\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "n_classes = 3\n",
    "n_boxes = 5\n",
    "partial_layer = 18\n",
    "\n",
    "start = time.time()\n",
    "imageNet_data = ImageNet_data(\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_img\",\n",
    "\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_bbox\", \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt\", n_classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing with serial_load backup weight\n"
     ]
    }
   ],
   "source": [
    "trained_model = Darknet19()\n",
    "serializers.load_npz(trained_weight_file, trained_model) # load saved model\n",
    "trained_model = Darknet19Predictor(trained_model)\n",
    "if initial_weight_file is None:\n",
    "    print(\"inititializing with the darknet19_448 weights\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    copy_conv_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bias_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bn_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "elif not (snapshot is None) :\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_npz(snapshot, model)\n",
    "\n",
    "else :\n",
    "    print(\"initializing with serial_load backup weight\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_hdf5(initial_weight_file, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predictor.train = True\n",
    "model.predictor.finetune = False  ####or True ??\n",
    "cuda.get_device(0).use()\n",
    "model.to_gpu()\n",
    "\n",
    "optimizer = optimizers.MomentumSGD(lr=learning_rate, momentum=momentum)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "model.predictor.conv1.disable_update()\n",
    "model.predictor.conv2.disable_update()\n",
    "model.predictor.conv3.disable_update()\n",
    "model.predictor.conv4.disable_update()\n",
    "model.predictor.conv5.disable_update()\n",
    "model.predictor.conv6.disable_update()\n",
    "model.predictor.conv7.disable_update()\n",
    "model.predictor.conv8.disable_update()\n",
    "model.predictor.conv9.disable_update()\n",
    "model.predictor.conv10.disable_update()\n",
    "model.predictor.conv11.disable_update()\n",
    "model.predictor.conv12.disable_update()\n",
    "model.predictor.conv13.disable_update()\n",
    "model.predictor.conv14.disable_update()\n",
    "model.predictor.conv15.disable_update()\n",
    "model.predictor.conv16.disable_update()\n",
    "#model.predictor.conv17.disable_update()\n",
    "#model.predictor.conv18.disable_update()\n",
    "#model.predictor.conv19.disable_update()\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(weight_decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRNG = RandomState()\n",
    "\n",
    "\n",
    "DA_arg = Compose([ [ColorJitter(brightness=0, contrast=0.7, saturation=0.7, hue=0, prob=0.5)],   # or write [ColorJitter(), None]\n",
    "        BoxesToCoords(relative=False),              \n",
    "           HorizontalFlip(),\n",
    "           VerticalFlip(),\n",
    "         RandomShift(),\n",
    "         Expand((1, 3), prob=0.5),\n",
    "        ObjectRandomCrop(),\n",
    "        RandomRotate(360),\n",
    "       Resize(448),   \n",
    "        CoordsToBoxesYOLO(),\n",
    "\n",
    "        #[SubtractMean(mean=VOC.MEAN)],\n",
    "        ], \n",
    "        PRNG, \n",
    "        mode='linear', \n",
    "        fillval=0, \n",
    "        outside_points='clamp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we transform data set for train\n"
     ]
    }
   ],
   "source": [
    "reporter = chainer.Reporter()\n",
    "\n",
    "\n",
    "#Create Train and test datset\n",
    "train, test = imageNet_data.train_val_test()\n",
    "\n",
    "#Transformed dataset, first creating function\n",
    "train_transf1 = partial(data_augmentation, transformDA=DA_arg)\n",
    "print(\"we transform data set for train\")\n",
    "train_trans1 = TransformDataset(train, train_transf1)\n",
    "\n",
    "train_iter = iterators.SerialIterator(train_trans1, batch_size)\n",
    "#train_iter = iterators.SerialIterator(train, batch_size)\n",
    "test_iter = iterators.SerialIterator(test, batch_size, repeat=False, shuffle=True)\n",
    "test=1\n",
    "val_interval = (1 if test else 100000), 'epoch'\n",
    "log_interval = (10 if test else 1000), 'iteration'\n",
    "\n",
    "\n",
    "\n",
    "with chainer.using_config('debug', True):\n",
    "    # Set up a trainer\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, loss_func=model, converter=convert, device=0)\n",
    "    trainer = training.Trainer(updater, (100, 'epoch'), out=\"./backup/result\")\n",
    "updater.connect_trainer(trainer)\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, converter=convert, device=0), trigger=val_interval)\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "# Take a snapshot at each epoch\n",
    "#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))\n",
    "trainer.extend(extensions.snapshot(), trigger=(20, 'epoch'))\n",
    "trainer.extend(save_model,  trigger=(10, 'epoch'))\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "trainer.extend(extensions.PrintReport(\n",
    "      ['epoch', 'main/images', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=log_interval)\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "\n",
    "# Plot graph for loss for each epoch\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/loss', 'validation/main/loss'],\n",
    "        x_key='epoch', file_name='loss.png'))\n",
    "else:\n",
    "    print('Warning: PlotReport is not available in your environment')\n",
    "# Print a progress bar to stdout\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [253.63215766880091, 117.76551245088766, 375.6267916909196, 242.23086437718274]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.35 0.61 0.41 0.34 2.   0.   0.   1.  ]] t_label  [[0.70229793 0.40178167 0.27230945 0.27782445 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e46fd0>] after YOLO computation [[253, 117, 375, 242]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [0.0, 0.0, 336.80864892302264, 348.3256510416667]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.6  0.57 0.61 0.83 2.   0.   0.   1.  ]] t_label  [[0.37590251 0.38875631 0.75180502 0.77751261 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e46fd0>] after YOLO computation [[0, 0, 336, 348]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [41.74940074573864, 52.40698414725044, 437.1790455638112, 261.2355689598056]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.28 0.43 0.16 0.68 0.   1.   0.   0.  ]] t_label  [[0.53451836 0.35004749 0.88265546 0.46613523 0.         1.\n",
      "  0.         0.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e461d0>] after YOLO computation [[41, 52, 437, 261]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [167.43539915966386, 128.14655002626048, 354.89436712184875, 306.0443146008403]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.45 0.48 0.52 0.61 2.   0.   0.   1.  ]] t_label  [[0.58295733 0.48458802 0.4184352  0.39709322 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e461d0>] after YOLO computation [[167, 128, 354, 306]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [218.07597503149498, 202.9136053856383, 417.1924123390258, 405.09471672032475]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.41 0.53 0.76 0.74 2.   0.   0.   1.  ]] t_label  [[0.7090049  0.67858072 0.44445633 0.45129712 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e461d0>] after YOLO computation [[218, 202, 417, 405]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [0.0, 0.0, 287.3126590780543, 227.57123859415373]\n",
      "SSD format output [0.0, 23.741915286357393, 445.97285067873304, 446.8423772609819]\n",
      "SSD format output [445.97285067873304, 316.7827135820413, 445.97285067873304, 316.7827135820413]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.5  0.16 1.   0.33 2.   0.   0.   1.  ]\n",
      " [0.32 0.61 0.64 0.78 2.   0.   0.   1.  ]\n",
      " [0.82 0.62 0.36 0.75 2.   0.   0.   1.  ]] t_label  [[0.32066145 0.25398576 0.6413229  0.50797151 2.         0.\n",
      "  0.         1.        ]\n",
      " [0.49773756 0.52520568 0.99547511 0.94442067 2.         0.\n",
      "  0.         1.        ]\n",
      " [0.99547511 0.70710427 0.         0.         2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e46668>, <lib.utils.Box object at 0x7f50e46b70>, <lib.utils.Box object at 0x7f50e46898>] after YOLO computation [[0, 0, 287, 227], [0, 23, 445, 446], [445, 316, 445, 316]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [74.02375793457031, 0.0, 447.0, 423.63177490234375]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.5  0.31 1.   0.63 1.   0.   1.   0.  ]] t_label  [[0.58149973 0.47280332 0.83253625 0.94560664 1.         0.\n",
      "  1.         0.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49fd0>] after YOLO computation [[74, 0, 447, 423]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [306.55668034372235, 121.9500292817813, 447.0, 205.84867356549458]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.44 0.45 0.35 0.85 1.   0.   1.   0.  ]] t_label  [[0.84102308 0.36584677 0.31348955 0.18727376 1.         0.\n",
      "  1.         0.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49f98>] after YOLO computation [[306, 121, 447, 205]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [85.47646428250718, 150.96045963541667, 446.2835249042146, 446.80533333333335]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.41 0.72 0.83 0.56 2.   0.   0.   1.  ]] t_label  [[0.59348213 0.66714932 0.8053729  0.66036802 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49fd0>] after YOLO computation [[85, 150, 446, 446]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [0.0, 10.912335304669288, 446.95081967213116, 446.9557109557109]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.51 0.51 0.75 0.98 2.   0.   0.   1.  ]] t_label  [[0.49882904 0.51101344 0.99765808 0.97331111 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49f98>] after YOLO computation [[0, 10, 446, 446]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [0.0, 95.64299774169922, 211.9797821044922, 396.5363464355469]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.68 0.74 0.55 0.52 2.   0.   0.   1.  ]] t_label  [[0.23658458 0.5493073  0.47316916 0.67163694 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49fd0>] after YOLO computation [[0, 95, 211, 396]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [0.0, 26.97585693359375, 446.2292490118577, 379.7567578125]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.47 0.52 0.51 0.94 2.   0.   0.   1.  ]] t_label  [[0.49802372 0.45394265 0.99604743 0.78745737 2.         0.\n",
      "  0.         1.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50c49f98>] after YOLO computation [[0, 26, 446, 379]]\n",
      "img shape (3, 448, 448)\n",
      "448 448 in YOLO convertor\n",
      "SSD format output [96.99308575324292, 242.042362830033, 439.86765919811324, 446.5214521452145]\n",
      "transformed_image (448, 448, 3)\n",
      "boxes from in_label [[0.45 0.78 0.43 0.43 1.   0.   1.   0.  ]] t_label  [[0.59917494 0.7684864  0.76534503 0.45642654 1.         0.\n",
      "  1.         0.        ]] yolo_show 8x,y,w,h) [<lib.utils.Box object at 0x7f50e5b278>] after YOLO computation [[96, 242, 439, 446]]\n",
      "\u001b[J"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cf2931af3426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0min_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_end\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_end\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/dataset/dataset_mixin.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/datasets/transform_dataset.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/sdmount/sdcard/YOLOv2-master/transforms/transforms.py\u001b[0m in \u001b[0;36mdata_augmentation\u001b[0;34m(inputs, transformDA, train, show)\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imageInit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1547\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1548\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with chainer.using_config('debug', True):\n",
    "    print(\"start\")\n",
    "    # Run the training\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_hdf5(\"%s/yolov2_final.model\" % (\"./backup/result\"), model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
