{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import chainer\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from chainer import serializers, optimizers, Variable, iterators,training, cuda\n",
    "from chainer.datasets import TransformDataset\n",
    "from chainer.training import extensions\n",
    "from chainer import Reporter, report, report_scope\n",
    "import chainer.functions as F\n",
    "from yolov2 import *\n",
    "from lib.utils import *\n",
    "from lib.preprocess import _offset_boxes, clip_boxes\n",
    "#from lib.image_generator import *\n",
    "from lib.data_generator import *\n",
    "from darknet19 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_conv_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.conv%d\" % i)\n",
    "        dst_layer = eval(\"dst.conv%d\" % i)\n",
    "        dst_layer.W = src_layer.W\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bias_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bias%d\" % i)\n",
    "        dst_layer = eval(\"dst.bias%d\" % i)\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bn_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bn%d\" % i)\n",
    "        dst_layer = eval(\"dst.bn%d\" % i)\n",
    "        dst_layer.N = src_layer.N\n",
    "        dst_layer.avg_var = src_layer.avg_var\n",
    "        dst_layer.avg_mean = src_layer.avg_mean\n",
    "        dst_layer.gamma = src_layer.gamma\n",
    "        dst_layer.eps = src_layer.eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert(batch, device):\n",
    "\n",
    "    #for pair in batch:\n",
    "        #print(pair[1])\n",
    "    return chainer.dataset.convert.concat_examples(batch, device, padding=0)\n",
    "\n",
    "def print_obs(t):\n",
    "    print(\"trainer.observation\", trainer.observation)\n",
    "    print(\"updater.loss\", updater.loss_func)\n",
    "    \n",
    "def save_model(t):\n",
    "    \n",
    "    serializers.save_hdf5(\"%s/yolov2_load.model\" % (\"./backup/result\"), model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "#train_sizes = [320, 352, 384, 416, 448]\n",
    "#train_sizes = [448]\n",
    "initial_weight_file = \"./backup/result/yolov2_load.model\"\n",
    "#initial_weight_file = None\n",
    "trained_weight_file = \"./darknet19_448.model\"\n",
    "snapshot=None\n",
    "#snapshot = \"./backup/result/snapshot_iter_4968\"\n",
    "backup_path = \"backup\"\n",
    "backup_file = \"%s/backup.model\" % (backup_path)\n",
    "batch_size =6\n",
    "epoch = 1000\n",
    "max_batches = 20000\n",
    "learning_rate = 1e-5\n",
    "learning_schedules = { \n",
    "    \"0\"    : 1e-5,\n",
    "    \"500\"  : 1e-4,\n",
    "    \"10000\": 1e-5,\n",
    "    \"20000\": 1e-6 \n",
    "}\n",
    "\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "n_classes = 3\n",
    "n_boxes = 5\n",
    "partial_layer = 18\n",
    "\n",
    "start = time.time()\n",
    "imageNet_data = ImageNet_data(\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_img\",\n",
    "\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_bbox\", \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt\", n_classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing with serial_load backup weight\n"
     ]
    }
   ],
   "source": [
    "trained_model = Darknet19()\n",
    "serializers.load_npz(trained_weight_file, trained_model) # load saved model\n",
    "trained_model = Darknet19Predictor(trained_model)\n",
    "if initial_weight_file is None:\n",
    "    print(\"inititializing with the darknet19_448 weights\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    copy_conv_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bias_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bn_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "elif not (snapshot is None) :\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_npz(snapshot, model)\n",
    "\n",
    "else :\n",
    "    print(\"initializing with serial_load backup weight\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_hdf5(initial_weight_file, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predictor.train = True\n",
    "model.predictor.finetune = False  ####or True ??\n",
    "cuda.get_device(0).use()\n",
    "model.to_gpu()\n",
    "\n",
    "optimizer = optimizers.MomentumSGD(lr=learning_rate, momentum=momentum)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "model.predictor.conv1.disable_update()\n",
    "model.predictor.conv2.disable_update()\n",
    "model.predictor.conv3.disable_update()\n",
    "model.predictor.conv4.disable_update()\n",
    "model.predictor.conv5.disable_update()\n",
    "model.predictor.conv6.disable_update()\n",
    "model.predictor.conv7.disable_update()\n",
    "model.predictor.conv8.disable_update()\n",
    "model.predictor.conv9.disable_update()\n",
    "model.predictor.conv10.disable_update()\n",
    "model.predictor.conv11.disable_update()\n",
    "model.predictor.conv12.disable_update()\n",
    "model.predictor.conv13.disable_update()\n",
    "model.predictor.conv14.disable_update()\n",
    "model.predictor.conv15.disable_update()\n",
    "model.predictor.conv16.disable_update()\n",
    "#model.predictor.conv17.disable_update()\n",
    "#model.predictor.conv18.disable_update()\n",
    "#model.predictor.conv19.disable_update()\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(weight_decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(inputs, train=True):\n",
    "    #we take only one input\n",
    "    img, label= inputs\n",
    "    boxes = label.copy()\n",
    "    im = img.copy()\n",
    "    im = np.asarray(im, dtype=np.float32) /255.0\n",
    "    im = np.transpose(im, (1, 2, 0))\n",
    "    shape= im.shape\n",
    "    #random_angle = np.random.uniform(0, 360)\n",
    "    im, trans_param = imcv2_affine_trans(im)\n",
    "    scale, offs, flip = trans_param\n",
    "    print(\"label\", label, \"scale, offs, flip\", scale, offs, flip, \"shape init\" , shape)\n",
    "    boxes = _offset_boxes(boxes, im.shape, scale, offs, flip)\n",
    "    sample_image = im.copy()\n",
    "    boxes = np.asarray(boxes, dtype=np.float32)\n",
    "    print(\"box\", boxes)\n",
    "    box = Box(boxes[0][1]*shape(1), boxes[0][2]*shape(0), boxes[0][3]*shape(1),boxes[0][4]*shape(0))\n",
    "    cv2.rectangle(\n",
    "               sample_image,\n",
    "               box.int_left_top(), box.int_right_bottom(),\n",
    "               (255, 0, 255),\n",
    "               3\n",
    "           )\n",
    "    cv2.imshow(\"image\", sample_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"label\", boxes)\n",
    "    im = cv2.resize(im, shape)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = imcv2_recolor(im)\n",
    "    return img, label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we transform data set for train\n"
     ]
    }
   ],
   "source": [
    "reporter = chainer.Reporter()\n",
    "\n",
    "\n",
    "#Create Train and test datset\n",
    "train, test = imageNet_data.train_val_test()\n",
    "\n",
    "#Transformed dataset, first creating function\n",
    "train_transf1 = partial(transform)\n",
    "print(\"we transform data set for train\")\n",
    "train_trans1 = TransformDataset(train, train_transf1)\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batch_size)\n",
    "test_iter = iterators.SerialIterator(test, batch_size, repeat=False, shuffle=True)\n",
    "test=1\n",
    "val_interval = (1 if test else 100000), 'epoch'\n",
    "log_interval = (30 if test else 1000), 'iteration'\n",
    "\n",
    "\n",
    "\n",
    "with chainer.using_config('debug', True):\n",
    "    # Set up a trainer\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, loss_func=model, converter=convert, device=0)\n",
    "    trainer = training.Trainer(updater, (100, 'epoch'), out=\"./backup/result\")\n",
    "updater.connect_trainer(trainer)\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, converter=convert, device=0), trigger=val_interval)\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "# Take a snapshot at each epoch\n",
    "#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))\n",
    "trainer.extend(extensions.snapshot(), trigger=(20, 'epoch'))\n",
    "trainer.extend(save_model,  trigger=(10, 'epoch'))\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport(trigger=log_interval))\n",
    "trainer.extend(extensions.PrintReport(\n",
    "      ['epoch', 'main/images', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=log_interval)\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "\n",
    "# Plot graph for loss for each epoch\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/loss', 'validation/main/loss'],\n",
    "        x_key='epoch', file_name='loss.png'))\n",
    "else:\n",
    "    print('Warning: PlotReport is not available in your environment')\n",
    "# Print a progress bar to stdout\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "label [[0.94 0.69 0.11 0.59 2.   0.   0.   1.  ]\n",
      " [0.3  0.55 0.52 0.89 2.   0.   0.   1.  ]] scale, offs, flip 1.0860873500867587 [35, 6] False shape init (448, 448, 3)\n",
      "box [[0.         0.         0.         0.64079154 2.1721747  0.\n",
      "  0.         1.0860873 ]\n",
      " [0.         0.         0.         0.96661776 2.1721747  0.\n",
      "  0.         1.0860873 ]]\n",
      "\u001b[J"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in main training loop: 'tuple' object is not callable\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/training/trainer.py\", line 304, in run\n",
      "    update()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\", line 149, in update\n",
      "    self.update_core()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\", line 153, in update_core\n",
      "    batch = self._iterators['main'].next()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\", line 81, in __next__\n",
      "    batch = [self.dataset[index] for index in self._order[i:i_end]]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\", line 81, in <listcomp>\n",
      "    batch = [self.dataset[index] for index in self._order[i:i_end]]\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/dataset/dataset_mixin.py\", line 67, in __getitem__\n",
      "    return self.get_example(index)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/chainer/datasets/transform_dataset.py\", line 47, in get_example\n",
      "    return self._transform(in_data)\n",
      "  File \"<ipython-input-37-25876a823fe5>\", line 17, in transform\n",
      "    box = Box(boxes[0][1]*shape(1), boxes[0][2]*shape(0), boxes[0][3]*shape(1),boxes[0][4]*shape(0))\n",
      "Will finalize trainer extensions and updater before reraising the exception.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cf2931af3426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 f.write('Will finalize trainer extensions and updater before '\n\u001b[1;32m    317\u001b[0m                         'reraising the exception.\\n')\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0min_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_end\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/iterators/serial_iterator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_end\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/dataset/dataset_mixin.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/datasets/transform_dataset.py\u001b[0m in \u001b[0;36mget_example\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-25876a823fe5>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(inputs, train)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"box\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     cv2.rectangle(\n\u001b[1;32m     19\u001b[0m                \u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "with chainer.using_config('debug', True):\n",
    "    print(\"start\")\n",
    "    # Run the training\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializers.save_hdf5(\"%s/yolov2_final.model\" % (\"./backup/result\"), model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
