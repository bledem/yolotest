{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import chainer\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from chainer import serializers, optimizers, Variable, iterators,training, cuda\n",
    "from chainer.datasets import TransformDataset, ConcatenatedDataset\n",
    "from chainer.training import extensions\n",
    "from chainer import Reporter, report, report_scope\n",
    "import chainer.functions as F\n",
    "from yolov2 import *\n",
    "from lib.utils import *\n",
    "from lib.preprocess import _offset_boxes, clip_boxes\n",
    "from transforms.transforms import *\n",
    "#from lib.image_generator import *\n",
    "from lib.data_generator import *\n",
    "from darknet19 import *\n",
    "from numpy.random import RandomState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_conv_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.conv%d\" % i)\n",
    "        dst_layer = eval(\"dst.conv%d\" % i)\n",
    "        dst_layer.W = src_layer.W\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bias_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bias%d\" % i)\n",
    "        dst_layer = eval(\"dst.bias%d\" % i)\n",
    "        dst_layer.b = src_layer.b\n",
    "\n",
    "def copy_bn_layer(src, dst, layers):\n",
    "    for i in layers:\n",
    "        src_layer = eval(\"src.bn%d\" % i)\n",
    "        dst_layer = eval(\"dst.bn%d\" % i)\n",
    "        dst_layer.N = src_layer.N\n",
    "        dst_layer.avg_var = src_layer.avg_var\n",
    "        dst_layer.avg_mean = src_layer.avg_mean\n",
    "        dst_layer.gamma = src_layer.gamma\n",
    "        dst_layer.eps = src_layer.eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Data augmentation parameter setting\n",
    "\n",
    "DA_arg = Compose([ [ColorJitter(brightness=0, contrast=0.5, saturation=0.5, hue=0, prob=0.5)],   # or write [ColorJitter(), None]\n",
    "            BoxesToCoords(relative=False),              \n",
    "               HorizontalFlip(),\n",
    "              # VerticalFlip(),\n",
    "             RandomShift(),\n",
    "             Expand((1, 2), prob=0.2),\n",
    "           # ObjectRandomCrop(),\n",
    "            RandomRotate(30),\n",
    "           Resize(416),   \n",
    "            CoordsToBoxesYOLO(),\n",
    "\n",
    "            #[SubtractMean(mean=VOC.MEAN)],\n",
    "            ], \n",
    "            RandomState(), \n",
    "            mode='linear', \n",
    "            fillval=0, \n",
    "            outside_points='clamp')\n",
    "nb_da = 0\n",
    "\n",
    "def convert_da(batch, device):\n",
    "    global nb_da\n",
    "    new_batch, nb_da = data_augmentation (batch, transformDA=DA_arg, show=False)\n",
    "    #print(len(new_batch), len(new_batch[0]))\n",
    "    return chainer.dataset.convert.concat_examples(batch, device, padding=0)\n",
    "\n",
    "def convert(batch, device):\n",
    "\n",
    "    return chainer.dataset.convert.concat_examples(batch, device, padding=0)\n",
    "\n",
    "\n",
    "def print_obs(t):\n",
    "    global nb_da\n",
    "    print(\"trainer.observation\", trainer.observation)\n",
    "    print(\"updater.loss\", updater.loss_func)\n",
    "    print(\"weight conv1\",model.predictor.conv1.W[0:2][0:2][0:2][0][0][0][0], model.predictor.conv1.b )\n",
    "    print(\"weight conv19\", model.predictor.conv19.W[0:2][0:2][0:2][0][0][0][0] ,model.predictor.conv19.b)\n",
    "    print(\"nb_da\", nb_da)\n",
    "\n",
    "def save_model(t):\n",
    "    print(\"epoch\", train_iter.epoch)\n",
    "    serializers.save_hdf5(\"%s/yolov2_load%s.model\" % (\"./backup/result\", str(train_iter.epoch) ), model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b0ceca13ad2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m imageNet_data = ImageNet_data(\"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_img\",\n\u001b[0;32m---> 34\u001b[0;31m \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/water_bottle_bbox\", \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt\", n_classes )\n\u001b[0m",
      "\u001b[0;32m/media/sdmount/sdcard/YOLOv2/lib/data_generator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, bbox_path, list_path, nb_class)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m#print(\"content\", content)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt'"
     ]
    }
   ],
   "source": [
    "###Variable Set Up \n",
    "\n",
    "# hyper parameters\n",
    "#train_sizes = [320, 352, 384, 416, 448]\n",
    "#train_sizes = [448]\n",
    "only_evaluation= False\n",
    "data_aug = True\n",
    "#initial_weight_file = \"./backup/result_12July_withDataAug/yolov2_load.model\"\n",
    "initial_weight_file = None\n",
    "trained_weight_file = \"./trained_weights/darknet_npz.model\"\n",
    "snapshot=None\n",
    "#snapshot = \"./backup/result/snapshot_iter_4968\"\n",
    "backup_path = \"backup\"\n",
    "backup_file = \"%s/backup.model\" % (backup_path)\n",
    "batch_size =6\n",
    "epoch = 1000\n",
    "max_batches = 20000\n",
    "learning_rate = 1e-5\n",
    "learning_schedules = { \n",
    "    \"0\"    : 1e-5,\n",
    "    \"500\"  : 1e-4,\n",
    "    \"10000\": 1e-5,\n",
    "    \"20000\": 1e-6 \n",
    "}\n",
    "lr_decay_power = 4\n",
    "momentum = 0.9\n",
    "weight_decay = 0.005\n",
    "n_classes = 3 #1003\n",
    "n_boxes = 5\n",
    "partial_layer = 18\n",
    "\n",
    "start = time.time()\n",
    "imageNet_data = ImageNet_data(\"/home/ubuntu/sdcard/YOLOv2/XmlToTxt/water_bottle_img\",\n",
    "\"/home/ubuntu/sdcard/YOLOv2/XmlToTxt/water_bottle_bbox\", \"/home/ubuntu/sdcard/YOLOv2-master/XmlToTxt/images_list.txt\", n_classes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inititializing with the ./darknet_npz.model weights\n"
     ]
    }
   ],
   "source": [
    "trained_model = Darknet19()\n",
    "serializers.load_npz(trained_weight_file, trained_model) # load saved model\n",
    "trained_model = Darknet19Predictor(trained_model)\n",
    "if initial_weight_file is None:\n",
    "    print(\"inititializing with the\",  trained_weight_file, \"weights\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    copy_conv_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bias_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    copy_bn_layer(trained_model.predictor, yolov2, range(1, partial_layer+1))\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "elif not (snapshot is None) :\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_npz(snapshot, model)\n",
    "\n",
    "else :\n",
    "    print(\"initializing with serial_load backup weight\")\n",
    "    yolov2 = YOLOv2(n_classes=n_classes, n_boxes=n_boxes)\n",
    "    model = YOLOv2Predictor(yolov2)\n",
    "    serializers.load_hdf5(initial_weight_file, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predictor.train = True\n",
    "model.predictor.finetune = False  ####or True ??\n",
    "cuda.get_device(0).use()\n",
    "model.to_gpu()\n",
    "\n",
    "optimizer = optimizers.MomentumSGD(lr=learning_rate, momentum=momentum)\n",
    "optimizer.use_cleargrads()\n",
    "optimizer.setup(model)\n",
    "model.predictor.conv1.disable_update()\n",
    "model.predictor.conv2.disable_update()\n",
    "model.predictor.conv3.disable_update()\n",
    "model.predictor.conv4.disable_update()\n",
    "model.predictor.conv5.disable_update()\n",
    "model.predictor.conv6.disable_update()\n",
    "model.predictor.conv7.disable_update()\n",
    "model.predictor.conv8.disable_update()\n",
    "model.predictor.conv9.disable_update()\n",
    "model.predictor.conv10.disable_update()\n",
    "model.predictor.conv11.disable_update()\n",
    "model.predictor.conv12.disable_update()\n",
    "model.predictor.conv13.disable_update()\n",
    "model.predictor.conv14.disable_update()\n",
    "model.predictor.conv15.disable_update()\n",
    "model.predictor.conv16.disable_update()\n",
    "model.predictor.conv17.disable_update()\n",
    "model.predictor.conv18.disable_update()\n",
    "model.predictor.conv19.disable_update()\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(weight_decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataAugm(training.Extension):\n",
    "    def __init__(self, count):\n",
    "       self._counter=count\n",
    "       #self._self_trigger= stop\n",
    "    def __call__(self, trainer, add_nb=1):\n",
    "        #self._counter+= add_nb\n",
    "        print(\"in class\",self._counter )\n",
    "#         trainer.reporter.add_observer('data_aug', observer_da)\n",
    "#         observation={}\n",
    "#         with reporter.scope(observation):\n",
    "#            trainer.reporter.report({'count': self._counter}, observer_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observer_da = object() \n",
    "test=1\n",
    "data_aug = False\n",
    "\n",
    "#Create Train and test datset\n",
    "train_normal, test_normal = imageNet_data.train_val_test()\n",
    "#print(\"check dataset indep1\",  train_normal[1] )\n",
    "\n",
    "\n",
    "train_iter = iterators.SerialIterator(train_normal, batch_size, shuffle=True)\n",
    "test_iter = iterators.SerialIterator(test_normal, batch_size, repeat=False, shuffle=True)\n",
    "\n",
    "val_interval = (1 if test else 100000), 'epoch'\n",
    "log_interval = (1 if test else 1000), 'iteration'\n",
    "\n",
    "\n",
    "with chainer.using_config('debug', True):\n",
    "    # Set up a trainer\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, loss_func=model, converter=convert_da, device=0)\n",
    "    trainer = training.Trainer(updater, (100, 'epoch'), out=\"./backup/result\")\n",
    "updater.connect_trainer(trainer)\n",
    "\n",
    "\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, converter=convert, device=0), trigger=val_interval)\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "#report({'da_images': da_nb, trainer)\n",
    "\n",
    "# Take a snapshot at each epoch\n",
    "#trainer.extend(extensions.snapshot(), trigger=(args.epoch, 'epoch'))\n",
    "trainer.extend(extensions.snapshot(), trigger=(20, 'epoch'))\n",
    "trainer.extend(print_obs, trigger=(10, 'iteration'))\n",
    "\n",
    "trainer.extend(save_model,  trigger=(10, 'epoch'))\n",
    "#trainer.extend(extensions.observe_value('count_da', lambda _: print(\"in l\", count_da)),  trigger=(1, 'iteration'))\n",
    "#trainer.extend(DataAugm(count_da))\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport(keys=['epoch', 'main/images', 'main/loss', \n",
    "                                          'validation/main/loss', 'elapsed_time'], trigger=log_interval))\n",
    "trainer.extend(extensions.PrintReport(\n",
    "      ['epoch', 'main/images', 'da_images', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=log_interval)\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "# Here \"main\" refers to the target link of the \"main\" optimizer again, and\n",
    "# \"validation\" refers to the default name of the Evaluator extension.\n",
    "# Entries other than 'epoch' are reported by the Classifier link, called by\n",
    "# either the updater or the evaluator.\n",
    "\n",
    "# Plot graph for loss for each epoch\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(extensions.PlotReport(\n",
    "        ['main/loss', 'validation/main/loss'],\n",
    "        x_key='epoch', file_name='loss.png'))\n",
    "else:\n",
    "    print('Warning: PlotReport is not available in your environment')\n",
    "# Print a progress bar to stdout\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and evaluation\n",
      "epoch       main/images  da_images   main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J0           6                        298.734                           16.3322       \n",
      "da batch\n",
      "\u001b[J"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1e1a3c87527e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training and evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0;31m# Run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_loop_exception_msg)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/training/updaters/standard_updater.py\u001b[0m in \u001b[0;36mupdate_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0min_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/optimizer.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, lossfun, *args, **kwds)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlossfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0muse_cleargrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_use_cleargrads'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_cleargrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sdmount/sdcard/YOLOv2-master/yolov2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_x, t)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0minput_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;31m#        print(\"type x in YOLOv2\", type(input_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m#number of images add for each batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/sdmount/sdcard/YOLOv2-master/yolov2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m###### new layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv20\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_resolution_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# output concatnation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias21\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn21\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv21\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/links/connection/convolution_2d.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m         return convolution_2d.convolution_2d(\n\u001b[1;32m    174\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             groups=self.groups)\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/functions/connection/convolution_2d.py\u001b[0m in \u001b[0;36mconvolution_2d\u001b[0;34m(x, W, b, stride, pad, cover_all, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    279\u001b[0m             if any(out.dtype.kind == 'f' and\n\u001b[1;32m    280\u001b[0m                    \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                    for out in outputs):\n\u001b[0m\u001b[1;32m    282\u001b[0m                 msg = ('NaN is detected on forward computation of '\n\u001b[1;32m    283\u001b[0m                        '{}'.format(self.label))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    279\u001b[0m             if any(out.dtype.kind == 'f' and\n\u001b[1;32m    280\u001b[0m                    \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                    for out in outputs):\n\u001b[0m\u001b[1;32m    282\u001b[0m                 msg = ('NaN is detected on forward computation of '\n\u001b[1;32m    283\u001b[0m                        '{}'.format(self.label))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with chainer.using_config('debug', True):\n",
    "    if (only_evaluation):\n",
    "        print(\"only evaluation\")\n",
    "        with chainer.using_config('enable_backprop', False) :\n",
    "            # Run the training\n",
    "            trainer.run()\n",
    "    else:\n",
    "        print(\"training and evaluation\")\n",
    "         # Run the training\n",
    "        trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "serializers.save_hdf5(\"%s/yolov2_final.model\" % (\"./backup/result\"), model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
